# Automate Real-World Data Collection Using Apify and Google Maps

## Task 1: Use Apify's Google Maps Scraper to extract business details
1. Set up an Apify account.
2. Create a new actor using the Google Maps Scraper.
3. Configure the scraper to extract business details such as name, address, phone number, and website.
4. Run the scraper and save the output in JSON format.

## Task 2: Store scraped data in a JSON format
1. Ensure the output from the Apify scraper is saved as a JSON file.
2. Verify the structure and content of the JSON file.
3. Store the JSON file in a designated directory for further processing.

## Task 3: Write a Python script to clean and format the data
1. Create a new Python script.
2. Load the JSON file containing the scraped data.
3. Clean and format the data to ensure consistency and accuracy.
4. Save the cleaned data in a new JSON file.

## Task 4: Automate data collection using Make (Integromat)
1. Set up a Make (Integromat) account.
2. Create a new scenario to automate the data collection process.
3. Integrate Apify with Make to trigger the Google Maps Scraper.
4. Schedule the scenario to run at regular intervals.

## Task 5: Store structured data in Supabase
1. Set up a Supabase project if not already done.
2. Create a table in Supabase to store the structured data.
3. Write a script to insert the cleaned data into the Supabase table.
4. Ensure the data is correctly stored and accessible for the directory application.

---

### Final Instructions
- Proceed step by step.
- Debug errors autonomously and retry failures 25 times before asking for intervention.
